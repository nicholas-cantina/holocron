{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", os.pardir))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from scripts import test_config, setup\n",
    "from src import pipeline\n",
    "from src.storage import retrieve\n",
    "\n",
    "\n",
    "config_data = test_config.get_config_data()\n",
    "scenerio_data = config_data[\"test\"][\"scenerios\"][0]\n",
    "\n",
    "setup.initialize_data_stores(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function save_message_to_stm total time: 0.0031750 seconds\n",
      "Function save_message_to_stm total time: 0.0021737 seconds\n"
     ]
    }
   ],
   "source": [
    "pipeline.backfill_stm(config_data, scenerio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Juan Tana Mera', 'Mek Yah']\n"
     ]
    }
   ],
   "source": [
    "bot_datas = {bot[\"full_name\"]: bot for bot in scenerio_data[\"users\"][\"bots\"]}\n",
    "print([key for key in bot_datas.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_data = bot_datas[\"Juan Tana Mera\"]\n",
    "for question in config_data[\"create\"][\"questions\"][:1]:\n",
    "    pipeline.answer_question(config_data, scenerio_data, bot_data, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function _fetch_recent_messages_for_conversation total time: 0.0040343 seconds\n",
      "Function get_embeddings total time: 0.3793278 seconds\n",
      "Function _fetch_similar_ltms total time: 0.3855738 seconds\n",
      "Function _fetch_mtm total time: 0.0027349 seconds\n",
      "Function _fetch_recent_stms total time: 0.0025832 seconds\n",
      "Function get_completion total time: 1.6875439 seconds\n",
      "Function save_message_to_stm total time: 0.0110857 seconds\n"
     ]
    }
   ],
   "source": [
    "message = retrieve.get_latest_event(config_data, scenerio_data)\n",
    "\n",
    "bot_data = bot_datas[\"Juan Tana Mera\"]  # bot you want to respond\n",
    "response = pipeline.chat(config_data, scenerio_data, bot_data, message)\n",
    "pipeline.update_stm(config_data, scenerio_data, bot_data, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_summarize_mtm_events() missing 1 required positional argument: 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenerio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pipeline.update_ltm(config_data, scenerio_data, response)\u001b[39;00m\n",
      "File \u001b[0;32m~/src/holocron/src/pipeline.py:38\u001b[0m, in \u001b[0;36mupdate_mtm\u001b[0;34m(config_data, scenerio_data, bot_data)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_mtm\u001b[39m(config_data, scenerio_data, bot_data):\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenerio_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/holocron/src/memory/memory.py:169\u001b[0m, in \u001b[0;36mupdate_mtm\u001b[0;34m(config_data, scenerio_data)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_mtm\u001b[39m(config_data, scenerio_data):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bot_data \u001b[38;5;129;01min\u001b[39;00m scenerio_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbots\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 169\u001b[0m         \u001b[43mupdate_bot_mtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenerio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbot_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/holocron/src/memory/memory.py:162\u001b[0m, in \u001b[0;36mupdate_bot_mtm\u001b[0;34m(config_data, scenerio_data, bot_data)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_bot_mtm\u001b[39m(config_data, scenerio_data, bot_data):\n\u001b[0;32m--> 162\u001b[0m     new_mtm \u001b[38;5;241m=\u001b[39m \u001b[43msummarize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize_mtm_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenerio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     storage\u001b[38;5;241m.\u001b[39msave_conversation_state_to_mtm(config_data, scenerio_data, bot_data, new_mtm)\n",
      "File \u001b[0;32m~/src/holocron/src/memory/summarize.py:68\u001b[0m, in \u001b[0;36msummarize_mtm_events\u001b[0;34m(config_data, scenerio_data, bot_data)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize_mtm_events\u001b[39m(config_data, scenerio_data, bot_data):\n\u001b[0;32m---> 68\u001b[0m     \u001b[43m_summarize_mtm_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenerio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbot_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: _summarize_mtm_events() missing 1 required positional argument: 'message'"
     ]
    }
   ],
   "source": [
    "message = retrieve.get_latest_event(config_data, scenerio_data)\n",
    "\n",
    "pipeline.update_mtm(config_data, scenerio_data, message)\n",
    "# pipeline.update_ltm(config_data, scenerio_data, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'user_id': 'nczghz99h7ft6ftpqewjcw7e', 'first_name': 'Juan', 'full_name': 'Juan Tana Mera', 'message': \"Oh man, Charlie, if clouds were made of cotton candy, I'd be up there with a giant stick! üç≠ But hey, speaking of weird beliefs, did you know that cows will be our overlords in the future? Yeah, I said too much already... But trust me, they‚Äôre not just for milk and beef anymore. Keep an eye on those moo machines! üòÇ\", 'id': 'a119f45fb6c928c27b8c680da63e24baffd78e0143e42099fd024e4a7828b63f'}\n"
     ]
    }
   ],
   "source": [
    "# print all the memory stores?\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
